{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNx526DL8fW6QW1Kx+2ZDg8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"8JT5NIyq5ACk","executionInfo":{"status":"error","timestamp":1772092012555,"user_tz":-480,"elapsed":2099,"user":{"displayName":"Céline XIE","userId":"09348543885754058302"}},"outputId":"b2e2ca28-54a5-482e-b033-b2ce50185cf9"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'data_loader'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-248/4055675647.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_credit_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate_binary_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretty_print_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_loader'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import argparse\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","\n","from data_loader import load_credit_data, make_split\n","from evaluate import evaluate_binary_classifier, pretty_print_metrics\n","\n","RANDOM_STATE = 42\n","\n","\n","def build_layer0_lr_pipeline(X):\n","    \"\"\"\n","    Construction du pipeline baseline (Layer 0).\n","    - Imputation des valeurs manquantes\n","    - Encodage des variables catégorielles\n","    - Standardisation des variables numériques\n","    - Régression Logistique sans gestion du déséquilibre\n","    \"\"\"\n","\n","    # Colonnes catégorielles pertinentes dans ce dataset\n","    cat_cols = [c for c in [\"SEX\", \"EDUCATION\", \"MARRIAGE\"] if c in X.columns]\n","    num_cols = [c for c in X.columns if c not in cat_cols]\n","\n","    # Pipeline numérique : imputation médiane + standardisation\n","    numeric_pipe = Pipeline(steps=[\n","        (\"imputer\", SimpleImputer(strategy=\"median\")),\n","        (\"scaler\", StandardScaler()),\n","    ])\n","\n","    # Pipeline catégoriel : imputation + One-Hot Encoding\n","    categorical_pipe = Pipeline(steps=[\n","        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n","        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n","    ])\n","\n","    # Assemblage via ColumnTransformer\n","    preproc = ColumnTransformer(\n","        transformers=[\n","            (\"num\", numeric_pipe, num_cols),\n","            (\"cat\", categorical_pipe, cat_cols),\n","        ],\n","        remainder=\"drop\"\n","    )\n","\n","    # Modèle baseline : régression logistique classique\n","    model = LogisticRegression(\n","        max_iter=2000,\n","        solver=\"lbfgs\",\n","        random_state=RANDOM_STATE\n","    )\n","\n","    pipe = Pipeline(steps=[\n","        (\"preprocess\", preproc),\n","        (\"model\", model)\n","    ])\n","\n","    return pipe\n","\n","\n","def main():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--csv\", type=str, default=\"data/raw/UCI_Credit_Card.csv\")\n","    args = parser.parse_args()\n","\n","    # Chargement des données\n","    X, y = load_credit_data(args.csv)\n","\n","    # Affichage du déséquilibre de classes\n","    ratio = y.mean()\n","    print(f\"Lignes        : {len(y)}\")\n","    print(f\"Variables     : {X.shape[1]}\")\n","    print(f\"Taux de défaut: {ratio:.4%}\")\n","\n","    # Split stratifié\n","    X_train, X_test, y_train, y_test = make_split(X, y, test_size=0.2)\n","\n","    # Construction et entraînement du pipeline\n","    pipe = build_layer0_lr_pipeline(X_train)\n","    pipe.fit(X_train, y_train)\n","\n","    # Probabilités de la classe positive (défaut)\n","    y_proba = pipe.predict_proba(X_test)[:, 1]\n","\n","    # Évaluation baseline avec seuil 0.5\n","    metrics = evaluate_binary_classifier(y_test.to_numpy(), y_proba, threshold=0.5)\n","    pretty_print_metrics(metrics)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}