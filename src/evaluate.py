{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPT7zl8y3iLRCWkzdMg9yAs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"8cRzAXzh1M-N","executionInfo":{"status":"ok","timestamp":1772092013320,"user_tz":-480,"elapsed":1451,"user":{"displayName":"Céline XIE","userId":"09348543885754058302"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    roc_auc_score, average_precision_score, confusion_matrix\n",")\n","\n","def evaluate_binary_classifier(y_true, y_proba, threshold=0.5):\n","    \"\"\"\n","    Évaluation complète d’un classifieur binaire.\n","    On transforme les probabilités en classes via un seuil donné.\n","    \"\"\"\n","\n","    # Conversion des probabilités en prédictions binaires\n","    y_pred = (y_proba >= threshold).astype(int)\n","\n","    out = {}\n","    out[\"threshold\"] = float(threshold)\n","    out[\"accuracy\"] = float(accuracy_score(y_true, y_pred))\n","    out[\"precision\"] = float(precision_score(y_true, y_pred, zero_division=0))\n","    out[\"recall\"] = float(recall_score(y_true, y_pred, zero_division=0))\n","    out[\"f1\"] = float(f1_score(y_true, y_pred, zero_division=0))\n","    out[\"roc_auc\"] = float(roc_auc_score(y_true, y_proba))\n","    out[\"pr_auc\"] = float(average_precision_score(y_true, y_proba))\n","\n","    # Matrice de confusion pour analyse des erreurs\n","    cm = confusion_matrix(y_true, y_pred)\n","    out[\"confusion_matrix\"] = cm.tolist()\n","    out[\"tn\"], out[\"fp\"], out[\"fn\"], out[\"tp\"] = map(int, cm.ravel())\n","\n","    return out\n","\n","\n","def pretty_print_metrics(m):\n","    \"\"\"\n","    Affichage formaté des métriques d’évaluation.\n","    \"\"\"\n","\n","    print(\"\\n=== Évaluation (Baseline Layer 0) ===\")\n","    print(f\"Seuil      : {m['threshold']:.2f}\")\n","    print(f\"Accuracy   : {m['accuracy']:.4f}\")\n","    print(f\"Precision  : {m['precision']:.4f}\")\n","    print(f\"Recall     : {m['recall']:.4f}\")\n","    print(f\"F1-score   : {m['f1']:.4f}\")\n","    print(f\"ROC-AUC    : {m['roc_auc']:.4f}\")\n","    print(f\"PR-AUC     : {m['pr_auc']:.4f}\")\n","    print(\"Matrice de confusion [[TN, FP],[FN, TP]]:\")\n","    print(np.array(m[\"confusion_matrix\"]))"]}]}